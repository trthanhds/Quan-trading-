{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file = r'D:\\6654305\\Du_An_Quan_Trading\\Booting\\features'\n",
    "files = [f for f in os.listdir(to_file) if f.endswith('.csv')]\n",
    "dfs = [pd.read_csv(os.path.join(to_file, file)) for file in files]\n",
    "df= pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol         0\n",
       "Market         0\n",
       "TradingDate    0\n",
       "Open           0\n",
       "High           0\n",
       "Low            0\n",
       "Close          0\n",
       "Volume         0\n",
       "Value          0\n",
       "SMA_20         0\n",
       "EMA_20         0\n",
       "RSI            0\n",
       "MACD           0\n",
       "Signal_Line    0\n",
       "Middle_Band    0\n",
       "Upper_Band     0\n",
       "Lower_Band     0\n",
       "TR             0\n",
       "ATR            0\n",
       "OBV            0\n",
       "VMA_20         0\n",
       "%K             0\n",
       "%D             0\n",
       "ROC            0\n",
       "MFI            0\n",
       "Williams_%R    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TradingDate'] = pd.to_datetime(df['TradingDate'], format='%d/%m/%Y', errors='coerce')\n",
    "df = df.drop(columns=\"Time\")\n",
    "df= df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Symbol', 'Market', 'TradingDate', 'Open', 'High', 'Low', 'Close',\n",
       "       'Volume', 'Value', 'SMA_20', 'EMA_20', 'RSI', 'MACD', 'Signal_Line',\n",
       "       'Middle_Band', 'Upper_Band', 'Lower_Band', 'TR', 'ATR', 'OBV', 'VMA_20',\n",
       "       '%K', '%D', 'ROC', 'MFI', 'Williams_%R'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 395697 entries, 19 to 401247\n",
      "Data columns (total 26 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Symbol       395697 non-null  object        \n",
      " 1   Market       395697 non-null  object        \n",
      " 2   TradingDate  395697 non-null  datetime64[ns]\n",
      " 3   Open         395697 non-null  int64         \n",
      " 4   High         395697 non-null  int64         \n",
      " 5   Low          395697 non-null  int64         \n",
      " 6   Close        395697 non-null  int64         \n",
      " 7   Volume       395697 non-null  int64         \n",
      " 8   Value        395697 non-null  float64       \n",
      " 9   SMA_20       395697 non-null  float64       \n",
      " 10  EMA_20       395697 non-null  float64       \n",
      " 11  RSI          395697 non-null  float64       \n",
      " 12  MACD         395697 non-null  float64       \n",
      " 13  Signal_Line  395697 non-null  float64       \n",
      " 14  Middle_Band  395697 non-null  float64       \n",
      " 15  Upper_Band   395697 non-null  float64       \n",
      " 16  Lower_Band   395697 non-null  float64       \n",
      " 17  TR           395697 non-null  int64         \n",
      " 18  ATR          395697 non-null  float64       \n",
      " 19  OBV          395697 non-null  int64         \n",
      " 20  VMA_20       395697 non-null  float64       \n",
      " 21  %K           395697 non-null  float64       \n",
      " 22  %D           395697 non-null  float64       \n",
      " 23  ROC          395697 non-null  float64       \n",
      " 24  MFI          395697 non-null  float64       \n",
      " 25  Williams_%R  395697 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(16), int64(7), object(2)\n",
      "memory usage: 81.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df[['SMA_20', 'EMA_20', 'RSI', 'MACD', 'Signal_Line',\n",
    "       'Middle_Band', 'Upper_Band', 'Lower_Band', 'ATR', 'OBV', 'VMA_20',\n",
    "       '%K', '%D', 'ROC', 'MFI', 'Williams_%R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "LB = LabelEncoder()\n",
    "df[\"Market\"] = LB.fit_transform(df[\"Market\"])\n",
    "df[\"Symbol\"]= LB.fit_transform(df[\"Symbol\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Market</th>\n",
       "      <th>TradingDate</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Value</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>...</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>TR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>OBV</th>\n",
       "      <th>VMA_20</th>\n",
       "      <th>%K</th>\n",
       "      <th>%D</th>\n",
       "      <th>ROC</th>\n",
       "      <th>MFI</th>\n",
       "      <th>Williams_%R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>18135</td>\n",
       "      <td>18619</td>\n",
       "      <td>18135</td>\n",
       "      <td>18135</td>\n",
       "      <td>3326740</td>\n",
       "      <td>1.005466e+11</td>\n",
       "      <td>19523.75</td>\n",
       "      <td>...</td>\n",
       "      <td>18518.734813</td>\n",
       "      <td>1149</td>\n",
       "      <td>1954.500000</td>\n",
       "      <td>-2051340</td>\n",
       "      <td>1490614.0</td>\n",
       "      <td>88.235294</td>\n",
       "      <td>92.549344</td>\n",
       "      <td>-8.805190</td>\n",
       "      <td>43.210657</td>\n",
       "      <td>-11.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>17833</td>\n",
       "      <td>18135</td>\n",
       "      <td>17289</td>\n",
       "      <td>17349</td>\n",
       "      <td>1645900</td>\n",
       "      <td>4.780900e+10</td>\n",
       "      <td>19441.70</td>\n",
       "      <td>...</td>\n",
       "      <td>18056.988881</td>\n",
       "      <td>846</td>\n",
       "      <td>1988.071429</td>\n",
       "      <td>-3697240</td>\n",
       "      <td>1494714.0</td>\n",
       "      <td>84.411035</td>\n",
       "      <td>88.824016</td>\n",
       "      <td>-13.011432</td>\n",
       "      <td>36.822450</td>\n",
       "      <td>-15.588965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>17833</td>\n",
       "      <td>18317</td>\n",
       "      <td>17833</td>\n",
       "      <td>18075</td>\n",
       "      <td>1366360</td>\n",
       "      <td>4.097755e+10</td>\n",
       "      <td>19393.05</td>\n",
       "      <td>...</td>\n",
       "      <td>17887.040917</td>\n",
       "      <td>968</td>\n",
       "      <td>1999.428571</td>\n",
       "      <td>-2330880</td>\n",
       "      <td>1490866.5</td>\n",
       "      <td>87.943366</td>\n",
       "      <td>86.863232</td>\n",
       "      <td>-10.537517</td>\n",
       "      <td>35.492251</td>\n",
       "      <td>-12.056634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>18135</td>\n",
       "      <td>18135</td>\n",
       "      <td>17410</td>\n",
       "      <td>17440</td>\n",
       "      <td>636390</td>\n",
       "      <td>1.857500e+10</td>\n",
       "      <td>19317.00</td>\n",
       "      <td>...</td>\n",
       "      <td>17582.801201</td>\n",
       "      <td>725</td>\n",
       "      <td>2005.785714</td>\n",
       "      <td>-2967270</td>\n",
       "      <td>1446024.5</td>\n",
       "      <td>84.853793</td>\n",
       "      <td>85.736064</td>\n",
       "      <td>-12.172030</td>\n",
       "      <td>30.086111</td>\n",
       "      <td>-15.146207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>17531</td>\n",
       "      <td>17531</td>\n",
       "      <td>17410</td>\n",
       "      <td>17440</td>\n",
       "      <td>375140</td>\n",
       "      <td>1.083959e+10</td>\n",
       "      <td>19246.70</td>\n",
       "      <td>...</td>\n",
       "      <td>17327.938766</td>\n",
       "      <td>121</td>\n",
       "      <td>1993.785714</td>\n",
       "      <td>-3342410</td>\n",
       "      <td>1407674.0</td>\n",
       "      <td>84.853793</td>\n",
       "      <td>85.883650</td>\n",
       "      <td>-12.308930</td>\n",
       "      <td>25.132793</td>\n",
       "      <td>-15.146207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401243</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>49300</td>\n",
       "      <td>50400</td>\n",
       "      <td>49200</td>\n",
       "      <td>49200</td>\n",
       "      <td>16700</td>\n",
       "      <td>8.268400e+08</td>\n",
       "      <td>50345.00</td>\n",
       "      <td>...</td>\n",
       "      <td>49549.023275</td>\n",
       "      <td>1200</td>\n",
       "      <td>985.714286</td>\n",
       "      <td>-66184</td>\n",
       "      <td>21565.0</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>-2.380952</td>\n",
       "      <td>37.708258</td>\n",
       "      <td>-94.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401244</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>49150</td>\n",
       "      <td>49150</td>\n",
       "      <td>48000</td>\n",
       "      <td>49000</td>\n",
       "      <td>222300</td>\n",
       "      <td>1.079681e+10</td>\n",
       "      <td>50280.00</td>\n",
       "      <td>...</td>\n",
       "      <td>49281.896535</td>\n",
       "      <td>1200</td>\n",
       "      <td>928.571429</td>\n",
       "      <td>-288484</td>\n",
       "      <td>29090.0</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>20.979532</td>\n",
       "      <td>-3.162055</td>\n",
       "      <td>19.479295</td>\n",
       "      <td>-79.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401245</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>49500</td>\n",
       "      <td>49900</td>\n",
       "      <td>48600</td>\n",
       "      <td>49000</td>\n",
       "      <td>11500</td>\n",
       "      <td>5.619800e+08</td>\n",
       "      <td>50180.00</td>\n",
       "      <td>...</td>\n",
       "      <td>49089.177037</td>\n",
       "      <td>1300</td>\n",
       "      <td>978.571429</td>\n",
       "      <td>-299984</td>\n",
       "      <td>26570.0</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>15.643275</td>\n",
       "      <td>-2.970297</td>\n",
       "      <td>20.259978</td>\n",
       "      <td>-79.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401246</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>49550</td>\n",
       "      <td>50000</td>\n",
       "      <td>48500</td>\n",
       "      <td>49500</td>\n",
       "      <td>9200</td>\n",
       "      <td>4.546800e+08</td>\n",
       "      <td>50105.00</td>\n",
       "      <td>...</td>\n",
       "      <td>49045.754986</td>\n",
       "      <td>1500</td>\n",
       "      <td>1035.714286</td>\n",
       "      <td>-290784</td>\n",
       "      <td>25985.0</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>24.305556</td>\n",
       "      <td>-1.394422</td>\n",
       "      <td>18.598583</td>\n",
       "      <td>-68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401247</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>49500</td>\n",
       "      <td>50000</td>\n",
       "      <td>49000</td>\n",
       "      <td>50000</td>\n",
       "      <td>10900</td>\n",
       "      <td>5.424600e+08</td>\n",
       "      <td>50080.00</td>\n",
       "      <td>...</td>\n",
       "      <td>49036.524027</td>\n",
       "      <td>1000</td>\n",
       "      <td>1071.428571</td>\n",
       "      <td>-279884</td>\n",
       "      <td>26385.0</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.788848</td>\n",
       "      <td>-58.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395697 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbol  Market TradingDate   Open   High    Low  Close   Volume  \\\n",
       "19           0       1  2018-01-29  18135  18619  18135  18135  3326740   \n",
       "20           0       1  2018-01-30  17833  18135  17289  17349  1645900   \n",
       "21           0       1  2018-01-31  17833  18317  17833  18075  1366360   \n",
       "22           0       1  2018-02-01  18135  18135  17410  17440   636390   \n",
       "23           0       1  2018-02-02  17531  17531  17410  17440   375140   \n",
       "...        ...     ...         ...    ...    ...    ...    ...      ...   \n",
       "401243      99       1  2024-11-04  49300  50400  49200  49200    16700   \n",
       "401244      99       1  2024-11-05  49150  49150  48000  49000   222300   \n",
       "401245      99       1  2024-11-06  49500  49900  48600  49000    11500   \n",
       "401246      99       1  2024-11-07  49550  50000  48500  49500     9200   \n",
       "401247      99       1  2024-11-08  49500  50000  49000  50000    10900   \n",
       "\n",
       "               Value    SMA_20  ...    Lower_Band    TR          ATR      OBV  \\\n",
       "19      1.005466e+11  19523.75  ...  18518.734813  1149  1954.500000 -2051340   \n",
       "20      4.780900e+10  19441.70  ...  18056.988881   846  1988.071429 -3697240   \n",
       "21      4.097755e+10  19393.05  ...  17887.040917   968  1999.428571 -2330880   \n",
       "22      1.857500e+10  19317.00  ...  17582.801201   725  2005.785714 -2967270   \n",
       "23      1.083959e+10  19246.70  ...  17327.938766   121  1993.785714 -3342410   \n",
       "...              ...       ...  ...           ...   ...          ...      ...   \n",
       "401243  8.268400e+08  50345.00  ...  49549.023275  1200   985.714286   -66184   \n",
       "401244  1.079681e+10  50280.00  ...  49281.896535  1200   928.571429  -288484   \n",
       "401245  5.619800e+08  50180.00  ...  49089.177037  1300   978.571429  -299984   \n",
       "401246  4.546800e+08  50105.00  ...  49045.754986  1500  1035.714286  -290784   \n",
       "401247  5.424600e+08  50080.00  ...  49036.524027  1000  1071.428571  -279884   \n",
       "\n",
       "           VMA_20         %K         %D        ROC        MFI  Williams_%R  \n",
       "19      1490614.0  88.235294  92.549344  -8.805190  43.210657   -11.764706  \n",
       "20      1494714.0  84.411035  88.824016 -13.011432  36.822450   -15.588965  \n",
       "21      1490866.5  87.943366  86.863232 -10.537517  35.492251   -12.056634  \n",
       "22      1446024.5  84.853793  85.736064 -12.172030  30.086111   -15.146207  \n",
       "23      1407674.0  84.853793  85.883650 -12.308930  25.132793   -15.146207  \n",
       "...           ...        ...        ...        ...        ...          ...  \n",
       "401243    21565.0   5.263158  26.315789  -2.380952  37.708258   -94.736842  \n",
       "401244    29090.0  20.833333  20.979532  -3.162055  19.479295   -79.166667  \n",
       "401245    26570.0  20.833333  15.643275  -2.970297  20.259978   -79.166667  \n",
       "401246    25985.0  31.250000  24.305556  -1.394422  18.598583   -68.750000  \n",
       "401247    26385.0  41.666667  31.250000   0.000000  22.788848   -58.333333  \n",
       "\n",
       "[395697 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Open_T+1\"] = df[\"Open\"].shift(-1)\n",
    "df[\"Close_T+3\"] = df[\"Close\"].shift(-3)\n",
    "df[\"Label\"] = (df[\"Close_T+3\"] > 1.02*df[\"Open_T+1\"]).astype(float)\n",
    "data= df.drop(columns=[\"Open_T+1\",\"Close_T+3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([288949.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0., 106748.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Open', 'High', 'Low', 'Volume', 'Value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"TradingDate\",\"Label\",\"Close\"])\n",
    "y= data[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data[data[\"TradingDate\"] < '2024-01-01']\n",
    "df_test = data[data[\"TradingDate\"] >= '2024-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chia du lieu train  test \n",
    "X_train,y_train = df_train.drop(columns=[\"TradingDate\",\"Label\",\"Close\"]),df_train[\"Label\"]\n",
    "X_test,y_test = df_test.drop(columns=[\"TradingDate\",\"Label\",\"Close\"]),df_test[\"Label\"]\n",
    "SS = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 344577 entries, 19 to 401034\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Symbol       344577 non-null  int32  \n",
      " 1   Market       344577 non-null  int32  \n",
      " 2   SMA_20       344577 non-null  float64\n",
      " 3   EMA_20       344577 non-null  float64\n",
      " 4   RSI          344577 non-null  float64\n",
      " 5   MACD         344577 non-null  float64\n",
      " 6   Signal_Line  344577 non-null  float64\n",
      " 7   Middle_Band  344577 non-null  float64\n",
      " 8   Upper_Band   344577 non-null  float64\n",
      " 9   Lower_Band   344577 non-null  float64\n",
      " 10  TR           344577 non-null  int64  \n",
      " 11  ATR          344577 non-null  float64\n",
      " 12  OBV          344577 non-null  int64  \n",
      " 13  VMA_20       344577 non-null  float64\n",
      " 14  %K           344577 non-null  float64\n",
      " 15  %D           344577 non-null  float64\n",
      " 16  ROC          344577 non-null  float64\n",
      " 17  MFI          344577 non-null  float64\n",
      " 18  Williams_%R  344577 non-null  float64\n",
      "dtypes: float64(15), int32(2), int64(2)\n",
      "memory usage: 49.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(X, posinf=np.max(X[np.isfinite(X)]), neginf=np.min(X[np.isfinite(X)]))\n",
    "\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()\n",
    "X_train = SS.fit_transform(X_train)\n",
    "X_test = SS.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train,y_train = smote.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.80      0.66     28203\n",
      "         1.0       0.47      0.21      0.29     22917\n",
      "\n",
      "    accuracy                           0.54     51120\n",
      "   macro avg       0.51      0.51      0.47     51120\n",
      "weighted avg       0.52      0.54      0.49     51120\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'y_pred_test_tree = model_tree.predict_proba(X_test)[:,1]\\n#Tính AUC trên tập kiểm tra\\nauc_test_tree = roc_auc_score(y_test, y_pred_test_tree)\\nprint(\"AUC test tree:\", auc_test_tree)\\n\\ny_pred_train_tree = model_tree.predict_proba(X_train)[:,1]\\nauc_train_tree = roc_auc_score(y_train,y_pred_train_tree)\\nprint(\"AUC train tree: \",auc_train_tree)\\nscores = cross_val_score(model_tree, X, y, cv=5, scoring=\\'roc_auc\\')\\nprint(\"AUC Cross_validation: \", scores.mean())'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=40,max_features='sqrt',min_samples_leaf=1,min_samples_split=2)\n",
    "model_tree.fit(X_train, y_train)\n",
    "y_pred_DT_SK = model_tree.predict(X_test)\n",
    "cr_DT = classification_report(y_pred_DT_SK,y_test)\n",
    "print(cr_DT)\n",
    "\n",
    "\n",
    "'''y_pred_test_tree = model_tree.predict_proba(X_test)[:,1]\n",
    "#Tính AUC trên tập kiểm tra\n",
    "auc_test_tree = roc_auc_score(y_test, y_pred_test_tree)\n",
    "print(\"AUC test tree:\", auc_test_tree)\n",
    "\n",
    "y_pred_train_tree = model_tree.predict_proba(X_train)[:,1]\n",
    "auc_train_tree = roc_auc_score(y_train,y_pred_train_tree)\n",
    "print(\"AUC train tree: \",auc_train_tree)\n",
    "scores = cross_val_score(model_tree, X, y, cv=5, scoring='roc_auc')\n",
    "print(\"AUC Cross_validation: \", scores.mean())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 248203, number of negative: 248203\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4438\n",
      "[LightGBM] [Info] Number of data points in the train set: 496406, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.08      0.15     40746\n",
      "         1.0       0.21      0.93      0.34     10374\n",
      "\n",
      "    accuracy                           0.25     51120\n",
      "   macro avg       0.51      0.51      0.24     51120\n",
      "weighted avg       0.70      0.25      0.19     51120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model_GBM = lgb.LGBMClassifier(\n",
    "    random_state=42,\n",
    "    num_leaves=31,            \n",
    "    max_depth=-2,             \n",
    "    learning_rate=0.1,       \n",
    "    n_estimators=200,    #Điều chỉnh số lượng cây \n",
    "    scale_pos_weight=10       \n",
    ")\n",
    "\n",
    "model_GBM.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test_GBM = model_GBM.predict(X_test)\n",
    "cr_GBM = classification_report(y_test,y_pred_test_GBM)\n",
    "print(cr_GBM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.81      0.32      9953\n",
      "         1.0       0.82      0.21      0.33     41167\n",
      "\n",
      "    accuracy                           0.33     51120\n",
      "   macro avg       0.51      0.51      0.33     51120\n",
      "weighted avg       0.70      0.33      0.33     51120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred_GBM_SK = model_GBM.predict(X_test)\n",
    "cr_GBM = classification_report(y_pred_GBM_SK,y_test)\n",
    "print(cr_GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC test MLP:  0.5905826690805263\n",
      "AUC train MLP:  0.6322363962166377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "model_MLP = MLPClassifier(hidden_layer_sizes=(20,20),max_iter=200)\n",
    "model_MLP.fit(X_train,y_train)\n",
    "y_pred_test_MLP = model_MLP.predict_proba(X_test)[:,1]\n",
    "\n",
    "AUC_test_MLP = roc_auc_score(y_test,y_pred_test_MLP)\n",
    "\n",
    "y_pred_train_MLP = model_MLP.predict_proba(X_train)[:,1]\n",
    "AUC_train_MLP = roc_auc_score(y_train,y_pred_train_MLP)\n",
    "\n",
    "print(\"AUC test MLP: \", AUC_test_MLP)\n",
    "print(\"AUC train MLP: \",AUC_train_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.80      0.89     51074\n",
      "         1.0       0.00      0.11      0.00        46\n",
      "\n",
      "    accuracy                           0.80     51120\n",
      "   macro avg       0.50      0.45      0.44     51120\n",
      "weighted avg       1.00      0.80      0.89     51120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_MLP_SK = model_MLP.predict(X_test)\n",
    "cr_MLP = classification_report(y_pred_MLP_SK,y_test)\n",
    "print(cr_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 248203, number of negative: 248203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 496406, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=15)),\n",
       "                (&#x27;lgbmclassifier&#x27;, LGBMClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=15)),\n",
       "                (&#x27;lgbmclassifier&#x27;, LGBMClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=15)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=15)),\n",
       "                ('lgbmclassifier', LGBMClassifier(random_state=42))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = PCA(n_components=15)  \n",
    "\n",
    "#PCA and GBM\n",
    "model_pipeline = make_pipeline(pca, lgb.LGBMClassifier(random_state=42))\n",
    "model_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC test tree: 0.581770812499951\n",
      "AUC train tree:  0.6851202806331614\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_tree = model_pipeline.predict_proba(X_test)[:, 1] \n",
    "\n",
    "\n",
    "auc_test_tree = roc_auc_score(y_test, y_pred_test_tree)\n",
    "print(\"AUC test tree:\", auc_test_tree)\n",
    "\n",
    "y_pred_train_tree = model_pipeline.predict_proba(X_train)[:,1]\n",
    "auc_train_tree = roc_auc_score(y_train,y_pred_train_tree)\n",
    "print(\"AUC train tree: \",auc_train_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 19)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m model_tf \u001b[38;5;241m=\u001b[39m Sequential([Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,),name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer_input\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m                        Dense(\u001b[38;5;241m512\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer_Dense_1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m                        Dropout(\u001b[38;5;241m.3\u001b[39m,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayyer_DropOut\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m                        Dense(\u001b[38;5;241m1\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer_Dense_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[0;32m      8\u001b[0m model_tf\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                  loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m                  metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mAUC(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m model_tf\u001b[38;5;241m.\u001b[39mevaluate(X_test,y_test)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegkqe4h7c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 19)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense,Dropout\n",
    "model_tf = Sequential([Input(shape=(19,),name = \"Layer_input\"),\n",
    "                       Dense(512,activation='relu',name=\"Layer_Dense_1\"),\n",
    "                       Dropout(.3,name=\"Layyer_DropOut\"),\n",
    "                       Dense(1,activation=\"softmax\",name=\"Layer_Dense_2\")])\n",
    "model_tf.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "model_tf.fit(X_train,y_train,epochs=5)\n",
    "model_tf.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
